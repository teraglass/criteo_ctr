{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49af2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "data_path = 'D:\\\\criteo_ctr_mlops\\\\data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ce816",
   "metadata": {},
   "source": [
    "- train - Training set. 10 days of click-through data, ordered chronologically. Non-clicks and clicks are subsampled according to different strategies.\n",
    "- test - Test set. 1 day of ads to for testing your model predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6eab1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\criteo_ctr_mlops\\\\data\\\\train.csv\", \"r\", encoding=\"utf-8\") as f_in, open(\"train_sample.csv\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i in range(100_001):\n",
    "        line = f_in.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        f_out.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100_000  # 10만 행씩 나눠서\n",
    "chunks = pd.read_csv(os.path.join(data_path, \"train.csv\"), chunksize=chunk_size)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # 각 chunk에 대해 전처리나 EDA\n",
    "    print(f\"Chunk {i} shape: {chunk.shape}\")\n",
    "    # 예: target 값 비율 확인\n",
    "    print(chunk['click'].value_counts(normalize=True))\n",
    "    if i == 5:\n",
    "        break  # 처음 6개만 샘플로 봄\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "775f0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80dabe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
       "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
       "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
       "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f7971b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_and_save(csv_path, output_dir, chunk_size=100_000):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    reader = pd.read_csv(csv_path, chunksize=chunk_size)\n",
    "    label_encoders = {}\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # 첫 번째 chunk에서 수치형 스케일링과 범주형 인코더 학습\n",
    "    first_chunk = next(reader)\n",
    "    num_cols = [col for col in first_chunk.columns if col.startswith('I')]\n",
    "    cat_cols = [col for col in first_chunk.columns if col.startswith('C')]\n",
    "\n",
    "    # 수치형 null 처리\n",
    "    first_chunk[num_cols] = first_chunk[num_cols].fillna(0)\n",
    "    scaler.fit(first_chunk[num_cols])\n",
    "\n",
    "    # 범주형 인코딩 학습\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(first_chunk[col].astype(str).fillna(''))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # 첫 chunk 다시 포함해서 반복\n",
    "    for i, chunk in enumerate(pd.read_csv(csv_path, chunksize=chunk_size)):\n",
    "        chunk[num_cols] = chunk[num_cols].fillna(0)\n",
    "        chunk[num_cols] = scaler.transform(chunk[num_cols])\n",
    "\n",
    "        for col in cat_cols:\n",
    "            chunk[col] = label_encoders[col].transform(chunk[col].astype(str).fillna(''))\n",
    "\n",
    "        # 저장\n",
    "        output_path = os.path.join(output_dir, f\"chunk_{i:03}.npz\")\n",
    "        np.savez_compressed(\n",
    "            output_path,\n",
    "            X=chunk[num_cols + cat_cols].values.astype(np.float32),\n",
    "            y=chunk[\"click\"].values.astype(np.float32)\n",
    "        )\n",
    "\n",
    "        print(f\"Saved {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5555f",
   "metadata": {},
   "source": [
    "### Retain (useful features):\n",
    "- click (target)\n",
    "- hour (extract day/hour from this)\n",
    "- C1, banner_pos (user context)\n",
    "- site_id, site_domain, site_category (site features)\n",
    "- app_id, app_domain, app_category (app features)\n",
    "- device_id, device_ip, device_model (device/user ID — may want to hash)\n",
    "- device_type, device_conn_type\n",
    "- C14~C21 (engineered categorical features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5b7d9",
   "metadata": {},
   "source": [
    "### isposable or to transform:\n",
    "- id: unique row identifier. Not predictive → drop\n",
    "- device_id, device_ip: may leak user info, and are high-cardinality. Either:\n",
    "- hash them into fixed buckets or drop them if not using high-cardinality methods (e.g., LightGBM can handle, but not basic DNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c7c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7adb3ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'flag'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\criteo_ctr_mlops\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'flag'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[32m      9\u001b[39m     df[col] = label_encoder.fit_transform(df[col])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m corr1 = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mflag\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.sort_values()\n\u001b[32m     13\u001b[39m plt.figure(figsize=(\u001b[32m20\u001b[39m,\u001b[32m2\u001b[39m))\n\u001b[32m     14\u001b[39m sns.heatmap(data = pd.DataFrame(corr1).T, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, annot_kws={\u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m12\u001b[39m}, fmt = \u001b[33m'\u001b[39m\u001b[33m.2f\u001b[39m\u001b[33m'\u001b[39m, linewidths=\u001b[32m0.5\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# .T\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\criteo_ctr_mlops\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\criteo_ctr_mlops\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'flag'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = df.columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "corr1 = df.corr()['flag'].sort_values()\n",
    "\n",
    "plt.figure(figsize=(20,2))\n",
    "sns.heatmap(data = pd.DataFrame(corr1).T, annot=True, annot_kws={\"size\": 12}, fmt = '.2f', linewidths=0.5, cmap='coolwarm') # .T\n",
    "plt.title('Correlation with Flag Variable', fontsize=20)\n",
    "plt.yticks(rotation=90)\n",
    "plt.tick_params(axis=\"x\", labelsize=13)\n",
    "plt.tick_params(axis=\"y\", labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22545df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8aa7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62da72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "criteo_ctr_mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
